{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opendatasets\n",
    "import opendatasets as od\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "dataset_link=\"https://www.kaggle.com/competitions/udea-ai4eng-20242\"\n",
    "od.download(dataset_link)\n",
    "#{\"username\":\"gonzandres\",\"key\":\"fa2731bdd837290a987f98515ff47e13\"}\n",
    "df =pd.read_csv(\"/content/udea-ai4eng-20242/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesing Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"RENDIMIENTO_GLOBAL_encoded\"] = pd.Categorical(\n",
    "    df[\"RENDIMIENTO_GLOBAL\"],\n",
    "    categories=[\"bajo\", \"medio-bajo\", \"medio-alto\", \"alto\"],\n",
    "    ordered=True, \n",
    ").codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_ESTU_PRGM_ACADEMICO_count = ['Muy raro', 'Raro', 'Poco común', 'Moderadamente popular', 'Popular', 'Muy Popular']\n",
    "\n",
    "order_PERIODO = [\n",
    "    20183,\n",
    "    20184,\n",
    "    20194,\n",
    "    20195,\n",
    "    20196,\n",
    "    20202,\n",
    "    20203,\n",
    "    20212,\n",
    "    20213,\n",
    "]\n",
    "\n",
    "order_ESTU_VALORMATRICULAUNIVERSIDAD = [\n",
    "    \"Menos de 500 mil\",\n",
    "    \"Entre 500 mil y menos de 1 millón\",\n",
    "    \"Entre 1 millón y menos de 2.5 millones\",\n",
    "    \"Entre 2.5 millones y menos de 4 millones\",\n",
    "    \"Entre 4 millones y menos de 5.5 millones\",\n",
    "    \"Entre 5.5 millones y menos de 7 millones\",\n",
    "    \"Más de 7 millones\",\n",
    "    \"No pagó matrícula\",\n",
    "]\n",
    "\n",
    "order_ESTU_HORASSEMANATRABAJA = [\n",
    "    \"0\",\n",
    "    \"Menos de 10 horas\",\n",
    "    \"Entre 11 y 20 horas\",\n",
    "    \"Entre 21 y 30 horas\",\n",
    "    \"Más de 30 horas\",\n",
    "]\n",
    "\n",
    "order_FAMI_ESTRATOVIVIENDA = [\n",
    "    \"Estrato 1\",\n",
    "    \"Estrato 2\",\n",
    "    \"Estrato 3\",\n",
    "    \"Estrato 4\",\n",
    "    \"Estrato 5\",\n",
    "    \"Estrato 6\",\n",
    "    \"Sin Estrato\",\n",
    "]\n",
    "\n",
    "order_FAMI_EDUCACION_PADRES = [\n",
    "    'Primaria incompleta',\n",
    "    'Primaria completa',\n",
    "    'Secundaria (Bachillerato) incompleta',\n",
    "    'Secundaria (Bachillerato) completa',\n",
    "    'Técnica o tecnológica incompleta',\n",
    "    'Técnica o tecnológica completa',\n",
    "    'Educación profesional incompleta',\n",
    "    'Educación profesional completa',\n",
    "    'Postgrado',\n",
    "    'Ninguno',\n",
    "]\n",
    "\n",
    "order_RENDIMIENTO_GLOBAL = [\"bajo\", \"medio-bajo\", \"medio-alto\", \"alto\"]\n",
    "\n",
    "ordinal_variables = [\n",
    "    \"ESTU_VALORMATRICULAUNIVERSIDAD\",\n",
    "    \"ESTU_HORASSEMANATRABAJA\",\n",
    "    \"FAMI_ESTRATOVIVIENDA\",\n",
    "    \"FAMI_EDUCACIONPADRE\",\n",
    "    \"FAMI_EDUCACIONMADRE\",\n",
    "]\n",
    "\n",
    "nominal_variables = [\n",
    "        \"ESTU_PRGM_DEPARTAMENTO\",\n",
    "        \"FAMI_TIENEINTERNET\",\n",
    "        \"ESTU_PAGOMATRICULAPROPIO\",\n",
    "    ]\n",
    "\n",
    "ordinal_categories = [\n",
    "    order_ESTU_VALORMATRICULAUNIVERSIDAD,     \n",
    "    order_ESTU_HORASSEMANATRABAJA,            \n",
    "    order_FAMI_ESTRATOVIVIENDA,               \n",
    "    order_FAMI_EDUCACION_PADRES,              \n",
    "    order_FAMI_EDUCACION_PADRES,                 \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_23676\\2379831712.py:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X['ESTU_PRGM_ACADEMICO'].fillna(-1, inplace=True)  # Assign -1 to unseen programs\n"
     ]
    }
   ],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Custom transformer using SentenceTransformer and KMeans clustering\n",
    "class ProgramClusterer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, num_clusters=15, model_name='distiluse-base-multilingual-cased-v2'):\n",
    "        self.num_clusters = num_clusters\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Extract unique programs\n",
    "        self.programs = X['ESTU_PRGM_ACADEMICO'].unique()\n",
    "\n",
    "        # Load the SentenceTransformer model\n",
    "        self.model = SentenceTransformer(self.model_name)\n",
    "\n",
    "        # Generate embeddings for the unique programs\n",
    "        self.embeddings = self.model.encode(self.programs)\n",
    "\n",
    "        # Perform KMeans clustering\n",
    "        self.kmeans = KMeans(n_clusters=self.num_clusters, random_state=42)\n",
    "        self.labels = self.kmeans.fit_predict(self.embeddings)\n",
    "\n",
    "        # Map programs to cluster labels\n",
    "        self.program_to_cluster = {program: label + 1 for program, label in zip(self.programs, self.labels)}\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Map programs to their clusters\n",
    "        X['ESTU_PRGM_ACADEMICO'] = X['ESTU_PRGM_ACADEMICO'].map(self.program_to_cluster)\n",
    "\n",
    "        # Handle programs not seen during fit\n",
    "        X['ESTU_PRGM_ACADEMICO'].fillna(-1, inplace=True)  # Assign -1 to unseen programs\n",
    "        return X\n",
    "\n",
    "# Ordinal encoding setup with handling unknown values\n",
    "ordinal_imputer = SimpleImputer(strategy='constant', fill_value=-1)\n",
    "ordinal_pipeline = Pipeline([\n",
    "    ('imputation', ordinal_imputer),\n",
    "    ('encoding', OrdinalEncoder(categories=ordinal_categories, handle_unknown='use_encoded_value', unknown_value=-1))\n",
    "])\n",
    "\n",
    "# One-hot encoding for nominal variables\n",
    "nominal_preprocessing = OneHotEncoder(drop='first', sparse_output=False)\n",
    "\n",
    "# Column transformer to apply transformations\n",
    "encoding_transformer = ColumnTransformer([\n",
    "    ('ordinal', ordinal_pipeline, ordinal_variables),\n",
    "    ('nominal', nominal_preprocessing, nominal_variables),\n",
    "])\n",
    "\n",
    "# Final pipeline with the custom ProgramClusterer\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('program_clustering', ProgramClusterer(num_clusters=15)),  # Replace the rare programs logic with clustering\n",
    "    ('encoding', encoding_transformer)\n",
    "])\n",
    "\n",
    "# Apply the pipeline to your DataFrame\n",
    "df_transformed = preprocessing_pipeline.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the NumPy array to a DataFrame\n",
    "df_transformed = pd.DataFrame(df_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (484750, 39) (484750,)\n",
      "Validation set: (69250, 39) (69250,)\n",
      "Test set: (138500, 39) (138500,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df[\"RENDIMIENTO_GLOBAL\"]\n",
    "X = df_transformed\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.125, random_state=42)\n",
    "# (0.125 * 0.8 = 0.1 of the original data for validation)\n",
    "\n",
    "print(\"Training set:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Selection\n",
    "\n",
    "Random Forests rank features by importance, which can provide insight into the most influential factors in predicting \"RENDIMIENTO_GLOBAL.\" This may be valuable for understanding which academic, financial, or familial factors correlate with performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.36758\n",
      "\n",
      "Classification Report on Validation Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        alto       0.49      0.50      0.49     17775\n",
      "        bajo       0.38      0.42      0.40     17231\n",
      "  medio-alto       0.29      0.26      0.28     17137\n",
      "  medio-bajo       0.29      0.28      0.28     17107\n",
      "\n",
      "    accuracy                           0.37     69250\n",
      "   macro avg       0.36      0.37      0.36     69250\n",
      "weighted avg       0.36      0.37      0.37     69250\n",
      "\n",
      "\n",
      "Test Accuracy: 0.37033\n",
      "\n",
      "Classification Report on Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        alto       0.49      0.51      0.50     35165\n",
      "        bajo       0.39      0.43      0.41     34573\n",
      "  medio-alto       0.29      0.25      0.27     34259\n",
      "  medio-bajo       0.29      0.29      0.29     34503\n",
      "\n",
      "    accuracy                           0.37    138500\n",
      "   macro avg       0.37      0.37      0.37    138500\n",
      "weighted avg       0.37      0.37      0.37    138500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=80, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Validate the model\n",
    "y_val_pred = rf_classifier.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.5f}\")\n",
    "\n",
    "# Detailed performance\n",
    "print(\"\\nClassification Report on Validation Set:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_test_pred = rf_classifier.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.5f}\")\n",
    "\n",
    "print(\"\\nClassification Report on Test Set:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 10 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "9 fits failed out of a total of 20.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 489, in fit\n",
      "    trees = Parallel(\n",
      "            ^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 192, in _parallel_build_trees\n",
      "    tree._fit(\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 472, in _fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n",
      "  File \"_tree.pyx\", line 172, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"_tree.pyx\", line 287, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"_tree.pyx\", line 942, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"_tree.pyx\", line 910, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"_utils.pyx\", line 35, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 16777216 bytes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 489, in fit\n",
      "    trees = Parallel(\n",
      "            ^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 192, in _parallel_build_trees\n",
      "    tree._fit(\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 472, in _fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n",
      "  File \"_tree.pyx\", line 172, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"_tree.pyx\", line 287, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"_tree.pyx\", line 942, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"_tree.pyx\", line 910, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"_utils.pyx\", line 35, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 8388608 bytes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 489, in fit\n",
      "    trees = Parallel(\n",
      "            ^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 192, in _parallel_build_trees\n",
      "    tree._fit(\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 472, in _fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n",
      "  File \"_tree.pyx\", line 172, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"_tree.pyx\", line 287, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"_tree.pyx\", line 942, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"_tree.pyx\", line 910, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"_utils.pyx\", line 35, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 4194304 bytes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 489, in fit\n",
      "    trees = Parallel(\n",
      "            ^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 192, in _parallel_build_trees\n",
      "    tree._fit(\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 472, in _fit\n",
      "    builder.build(self.tree_, X, y, sample_weight, missing_values_in_feature_mask)\n",
      "  File \"_tree.pyx\", line 172, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"_tree.pyx\", line 287, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"_tree.pyx\", line 942, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"_tree.pyx\", line 910, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"_utils.pyx\", line 35, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 2097152 bytes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 489, in fit\n",
      "    trees = Parallel(\n",
      "            ^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 74, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py\", line 136, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 192, in _parallel_build_trees\n",
      "    tree._fit(\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py\", line 305, in _fit\n",
      "    classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)\n",
      "                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\arraysetops.py\", line 274, in unique\n",
      "    ret = _unique1d(ar, return_index, return_inverse, return_counts,\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\arraysetops.py\", line 358, in _unique1d\n",
      "    imask = np.cumsum(mask) - 1\n",
      "            ^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 2586, in cumsum\n",
      "    return _wrapfunc(a, 'cumsum', axis=axis, dtype=dtype, out=out)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py\", line 59, in _wrapfunc\n",
      "    return bound(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 947. KiB for an array with shape (242375,) and data type int32\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\andre\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1103: UserWarning: One or more of the test scores are non-finite: [0.39670346        nan 0.39610727        nan        nan        nan\n",
      "        nan 0.39653017 0.39766065 0.38481073]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'n_estimators': 300, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'log2', 'max_depth': 30}\n",
      "Best cross-validation score:  0.39766064981949456\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_distributions = {\n",
    "    'n_estimators': [100, 300, 500],         # Number of trees\n",
    "    'max_depth': [None, 30, 50],           # Maximum depth of trees\n",
    "    'min_samples_split': [2, 5, 10],                   # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],                     # Minimum number of samples required at each leaf node\n",
    "    'max_features': ['sqrt', 'log2']           # Number of features to consider at each split\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize the RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=10,                  # Number of different combinations to try\n",
    "    cv=2,                       \n",
    "    scoring='accuracy',         # Evaluation metric\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=8                  # Use available cores\n",
    ")\n",
    "\n",
    "# Fit the random search to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best parameters found: \", random_search.best_params_)\n",
    "print(\"Best cross-validation score: \", random_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle Submission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load test data\n",
    "test_data = pd.read_csv(\"udea-ai4eng-20242/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_23676\\2379831712.py:38: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X['ESTU_PRGM_ACADEMICO'].fillna(-1, inplace=True)  # Assign -1 to unseen programs\n"
     ]
    }
   ],
   "source": [
    "# Apply the pipeline to your DataFrame\n",
    "df_transformed_test = preprocessing_pipeline.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the NumPy array to a DataFrame\n",
    "df_transformed_test = pd.DataFrame(df_transformed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = random_search.predict(df_transformed_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['bajo', 'medio-bajo', 'bajo', ..., 'medio-alto', 'alto', 'alto'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created:\n",
      "       ID RENDIMIENTO_GLOBAL\n",
      "0  550236               bajo\n",
      "1   98545         medio-bajo\n",
      "2  499179               bajo\n",
      "3  782980               bajo\n",
      "4  785185               bajo\n"
     ]
    }
   ],
   "source": [
    "# Define the mapping from encoded values to categorical labels\n",
    "category_labels = [\"bajo\", \"medio-bajo\", \"medio-alto\", \"alto\"]\n",
    "\n",
    "# Start with the ID column\n",
    "submission_df = test_data[[\"ID\"]].copy()\n",
    "submission_df[\"RENDIMIENTO_GLOBAL\"] = predictions\n",
    "# Save the submission file\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "print(\"Submission file created:\")\n",
    "print(submission_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV for submission\n",
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
